# -*- coding: utf-8 -*-
"""Model_Autoecoder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bG0BZa6IRSMWZh9q_si_HSGBOU9Hs9ef
"""

pip install h2o

import h2o
import matplotlib.pyplot as plt
from pylab import rcParams
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
from h2o.estimators.deeplearning import H2OAutoEncoderEstimator, H2ODeepLearningEstimator

h2o.init(max_mem_size = 2) # initializing h2o server
h2o.remove_all()

waterData = pd.read_csv('w.csv') 
waterData.describe()

waterData.shape

waterData.isnull().values.any()

waterData['pH'].fillna((waterData['pH'].mean()), inplace=True)
waterData['Tp'].fillna((waterData['Tp'].mean()), inplace=True)
waterData['Cond'].fillna((waterData['Cond'].mean()), inplace=True)
waterData['Turb'].fillna((waterData['Turb'].mean()), inplace=True)
waterData['SAC'].fillna((waterData['SAC'].mean()), inplace=True)
waterData['PFM'].fillna((waterData['PFM'].mean()), inplace=True)

waterData['pH'].isnull().sum()

#Turns python pandas frame into an H2OFrame
waterData_h2o  = h2o.H2OFrame(waterData)
TRUE= waterData[waterData.Event == 1]
FALSE = waterData[waterData.Event == 0]
# pH vs Event
f, (ax1, ax2) = plt.subplots(2,1,sharex=True)
f.suptitle('pH per detection by event')
ax1.hist(TRUE.pH, bins = 50)
ax1.set_title('True List')
ax2.hist(FALSE.pH, bins = 50)
ax2.set_title('false')
plt.xlabel('pH')
plt.ylabel('Number of detections')
plt.xlim(0, 10)
plt.yscale('log')
plt.show()

features= waterData_h2o.drop(['Time'], axis=1)

train, test = features.split_frame([0.90])
print(train.shape)
print(test.shape)

# converting to pandas dataframe
train_df = train.as_data_frame()
test_df = test.as_data_frame()
train_df = train_df[train_df['Event'] == 0]
# drop the Class variable
train_df = train_df.drop(['Event'], axis=1)
Y_test_df = test_df['Event'] # true labels of the testing set
test_df = test_df.drop(['Event'], axis=1)
train_df.shape

train_h2o = h2o.H2OFrame(train_df) # converting to h2o frame
test_h2o = h2o.H2OFrame(test_df)
x = train_h2o.columns

anomaly_model = H2ODeepLearningEstimator(activation = "Tanh",
                               hidden = [14,7,7,14],
                               epochs = 100,
                               standardize = True,
                                stopping_metric = 'MSE', 
                                loss = 'automatic',
                                train_samples_per_iteration = 32,
                                shuffle_training_data = True,     
                               autoencoder = True,
                               l1 = 10e-5)
anomaly_model.train(x=x, training_frame = train_h2o)

anomaly_model._model_json['output']['variable_importances'].as_data_frame()

# plotting the variable importance
rcParams['figure.figsize'] = 14, 8
#plt.rcdefaults()
fig, ax = plt.subplots()

variables = anomaly_model._model_json['output']['variable_importances']['variable']
var = variables[0:15]
y_pos = np.arange(len(var))

scaled_importance = anomaly_model._model_json['output']['variable_importances']['scaled_importance']
sc = scaled_importance[0:15]

ax.barh(y_pos, sc, align='center', color='green', ecolor='black')
ax.set_yticks(y_pos)
ax.set_yticklabels(variables)
ax.invert_yaxis()
ax.set_xlabel('Scaled Importance')
ax.set_title('Variable Importance')
plt.show()

#plotting the loss
scoring_history = anomaly_model.score_history()
# %matplotlib inline
rcParams['figure.figsize'] = 14, 8
plt.plot(scoring_history['training_mse'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')

test_rec_error = anomaly_model.anomaly(test_h2o) 
# anomaly is a H2O function which calculates the error for the dataset
# converting to pandas dataframe
test_rec_error_df = test_rec_error.as_data_frame()
# plotting the testing dataset against the error
test_rec_error_df['id']=test_rec_error_df.index
rcParams['figure.figsize'] = 14, 8
test_rec_error_df.plot(kind="scatter", x='id', y="Reconstruction.MSE")
plt.show()

# predicting the class for the testing dataset
predictions = anomaly_model.predict(test_h2o)
error_df = pd.DataFrame({'reconstruction_error': test_rec_error_df['Reconstruction.MSE'],
                        'true_class': Y_test_df})
error_df.describe()

# reconstruction error for the normal detections in the testing dataset
fig = plt.figure()
ax = fig.add_subplot(111)
rcParams['figure.figsize'] = 14, 8
false_error_df = error_df[(error_df['true_class']== 0) & (error_df['reconstruction_error'] < 10)]
_ = ax.hist(false_error_df.reconstruction_error.values, bins=10)

# reconstruction error for the fraud transactions in the testing dataset
fig = plt.figure()
ax = fig.add_subplot(111)
rcParams['figure.figsize'] = 14, 8
true_error_df = error_df[error_df['true_class'] == 1]
_ = ax.hist(false_error_df.reconstruction_error.values, bins=10)

from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,
                             roc_curve, recall_score, classification_report, f1_score,
                             precision_recall_fscore_support)
fpr, tpr, thresholds = roc_curve(error_df.true_class, error_df.reconstruction_error)
roc_auc = auc(fpr, tpr)
plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)
plt.legend(loc='lower right')
plt.plot([0,1],[0,1],'r--')
plt.xlim([-0.001, 1])
plt.ylim([0, 1.001])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show();

precision, recall, th = precision_recall_curve(error_df.true_class, error_df.reconstruction_error)
plt.plot(recall, precision, 'b', label='Precision-Recall curve')
plt.title('Recall vs Precision')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.show()

plt.plot(th, precision[1:], label="Precision",linewidth=5)
plt.plot(th, recall[1:], label="Recall",linewidth=5)
plt.title('Precision and recall for different threshold values')
plt.xlabel('Threshold')
plt.ylabel('Precision/Recall')
plt.legend()
plt.show()

# plot the testing set with the threshold
threshold = 0.01
groups = error_df.groupby('true_class')
fig, ax = plt.subplots()
for name, group in groups:
    ax.plot(group.index, group.reconstruction_error, marker='o', ms=3.5, linestyle='',
            label= "TRUE" if name == 1 else "FALSE")
ax.hlines(threshold, ax.get_xlim()[0], ax.get_xlim()[1], colors="r", zorder=100, label='Threshold')
ax.legend()
plt.title("Reconstruction error for different classes")
plt.ylabel("Reconstruction error")
plt.xlabel("Data point index")
plt.show();

import seaborn as sns
LABELS = ['FALSE', 'TRUE']
y_pred = [1 if e > threshold else 0 for e in error_df.reconstruction_error.values]
conf_matrix = confusion_matrix(error_df.true_class, y_pred)
plt.figure(figsize=(12, 12))
sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt="d");
plt.title("Confusion matrix")
plt.ylabel('True class')
plt.xlabel('Predicted class')
plt.show()

csr = classification_report(error_df.true_class, y_pred)
print(csr)

